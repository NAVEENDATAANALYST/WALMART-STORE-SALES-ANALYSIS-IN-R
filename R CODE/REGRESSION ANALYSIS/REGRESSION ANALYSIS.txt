#THIS CODE BELONGS TO ME. THE DATA SET U CAN FIND IN KAGGLE IN THIS LINK:https://www.kaggle.com/datasets/rutuspatel/walmart-dataset-retail

##REGRESSION ANALYSIS

#MULTIPLE LINEAR REGRESSION MODEL
lm(Weekly_Sales~Store+Holiday_Flag+Temperature+Fuel_Price+CPI+Unemployment,data=df)

#DROPPING THE INSIGNIFICANT VARIABLES FUEL PRICE AND UNEMPLOYMENT
lm(Weekly_Sales~Store+Holiday_Flag+Temperature+CPI,data=df)


#LETS BUILD A MULTIPLE LINEAR MODEL FOR ONLY STORE 1
Store1 <- select(filter(df,Store==1),-1)
Store1

Store1_lm <- lm(Weekly_Sales~Temperature+CPI+Unemployment,data=Store1)
#SUMMARY OF LINEAR REGRESSION MODEL
summary(Store1_lm)
#THE COEFFICIENT OF TEMPERATURE IS -2587.7 WHICH MEANS THAT FOR ONE DEGREE INCREASE IN TEMPERATURE THE WEEKLY SALES DECREASE BY 2587.7
#FROM THE MULTIPLE R-SQUARED VALUE WE CAN TELL THAT THE VARIABLES TEMPERATURE, CPI AND UNEMPLOYEMNT EXPLAINS 12.6% OF VARIATION IN SALES.

prediction <- predict(Store1_lm,newdata=list(Temperature=39,CPI=220,Unemployment=5.1))
prediction

accuracy(Store1_lm)

#PLOTTING THE DIAGNOSTIC PLOTS
par(mfrow=c(2,2))
plot(Store1_lm)


cor(Store1$Weekly_Sales,Store1$Temperature)
#THERE IS A WEAK NEGATIVE CORRELATION BETWEEN WEEKLY SALES OF STORE 1 AND TEMPERATURE

cor(Store1$Weekly_Sales,Store1$Fuel_Price)
#THERE IS A WEAK POSITIVE CORRELATION BETWEEN WEEKLY SALES OF STORE 1 AND FUEL PRICE

cor(Store1$Weekly_Sales,Store1$CPI)
#THERE IS A WEAK POSITIVE CORRELATION BETWEEN WEEKLY SALES OF STORE 1 AND CPI

cor(Store1$Weekly_Sales,Store1$Unemployment)
#THERE IS A WEAK NEGATIVE CORRELATION BETWEEN WEEKLY SALES OF STORE 1 AND UNEMPLOYMENT



#LOGISTIC REGRESSION

#CREATING VARIABLE HIGH SALES FOR CLASSIFICATION
df$high_sales <- ifelse(df$Weekly_Sales>median(df$Weekly_Sales),1,0)

#FITTING THE LOGISTIC REGRESSION MODEL
lr_model <- glm(high_sales~Temperature+Fuel_Price+CPI+Unemployment+Holiday_Flag,data=df,family=binomial)

#SUMMARY OF LOGISTIC REGRESSION MODEL
summary(lr_model)

#CHECKING OF GOODNESS OF FIT OF OUR MODEL USING HOSMER LEMESHOW TEST
hoslem.test(df$high_sales,predict(lr_model,type="response"))
#FROM THE TEST WE CAN TELL THAT IF THE P-VALUE IS GREATER THAN 0.05 WE CAN TELL THAT THE MODEL FITS THE DATA WELL. BUT HERE IT IS LESS THAN 0.05 SO WE NEED TO DROP INSIGNIFICANT VARIABLES.

#FITTING THE LOGISTIC REGRESSION MODEL AGAIN AFTER DROPPING INSIGNIFICANT VARIABLES
lr_model_1 <- glm(high_sales~Temperature+CPI,data=df,family=binomial)

#SUMMARY OF LOGISTIC REGRESSION MODEL
summary(lr_model_1)

#CHECKING OF GOODNESS OF FIT OF OUR MODEL USING HOSMER LEMESHOW TEST
hoslem.test(df$high_sales,predict(lr_model_1,type="response"))
#FROM THE TEST WE CAN TELL THAT THE P-VALUE IS 0.1476 WHICH IS GREATER THAN 0.05. SO WE CAN CONCLUDE THAT THE MODEL FITS THE DATA WELL.



#DECISION TREE

#CREATING DECISION TREE MODEL
dt_model <- rpart(Weekly_Sales ~ .,data=df)

#PLOTTING THE DECISION TREE
rpart.plot(dt_model)



#RANDOM FOREST

#CREATING RANDOM FOREST MODEL
rf_model <- randomForest(Weekly_Sales ~ .,data=df)

#MODEL SUMMARY
print(rf_model)

#FINDING IMPORTANT VARIABLES IN RANDOM FOREST MODEL
varImpPlot(rf_model)